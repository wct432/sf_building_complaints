{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13c3691",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5de45c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from src.pipeline_helpers import get_proportions\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import TFDistilBertModel, DistilBertConfig, DistilBertTokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9dcfe2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "data_path = os.path.dirname(working_dir) + '/data/'\n",
    "model_path = os.path.dirname(working_dir) + '/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "eaf05db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + 'preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0e37652e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_description</th>\n",
       "      <th>assigned_division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148462</th>\n",
       "      <td>Needs to renew boiler permit for permit no 960...</td>\n",
       "      <td>Plumbing Inspection Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114602</th>\n",
       "      <td>Drain in bathtub is slow.  leaky windows in be...</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86142</th>\n",
       "      <td>No violations found at the time of inspection-...</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162618</th>\n",
       "      <td>Buckets of gas</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>Attached c. green's letter dated - 3/16/95 (pa...</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84508</th>\n",
       "      <td>No heat, roach infestation and shower in basem...</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158143</th>\n",
       "      <td>Date last observed: 19-mar-19;    time last ob...</td>\n",
       "      <td>Building Inspection Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149530</th>\n",
       "      <td>Responding to an emergency call out form sfpd ...</td>\n",
       "      <td>Building Inspection Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54820</th>\n",
       "      <td>Big pile of junks - desk, wood, mattress in fr...</td>\n",
       "      <td>Building Inspection Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48074</th>\n",
       "      <td>Front door closer not working properly.  hinge...</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    complaint_description  \\\n",
       "148462  Needs to renew boiler permit for permit no 960...   \n",
       "114602  Drain in bathtub is slow.  leaky windows in be...   \n",
       "86142   No violations found at the time of inspection-...   \n",
       "162618                                     Buckets of gas   \n",
       "1314    Attached c. green's letter dated - 3/16/95 (pa...   \n",
       "84508   No heat, roach infestation and shower in basem...   \n",
       "158143  Date last observed: 19-mar-19;    time last ob...   \n",
       "149530  Responding to an emergency call out form sfpd ...   \n",
       "54820   Big pile of junks - desk, wood, mattress in fr...   \n",
       "48074   Front door closer not working properly.  hinge...   \n",
       "\n",
       "                   assigned_division  \n",
       "148462  Plumbing Inspection Division  \n",
       "114602   Housing Inspection Services  \n",
       "86142    Housing Inspection Services  \n",
       "162618   Housing Inspection Services  \n",
       "1314     Housing Inspection Services  \n",
       "84508    Housing Inspection Services  \n",
       "158143  Building Inspection Division  \n",
       "149530  Building Inspection Division  \n",
       "54820   Building Inspection Division  \n",
       "48074    Housing Inspection Services  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f359aa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complaint_description    0\n",
       "assigned_division        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d488a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.complaint_description\n",
    "y = df.assigned_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6a0b62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "17cde0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=.5, random_state = 42, stratify = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "81f5037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train proportions: \n",
      " {0: 0.35785110590354746, 1: 0.060562557617469266, 2: 0.48990506752239604, 3: 0.09170238070105066}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_proportions = get_proportions(y_train)\n",
    "print(f\"y_train proportions: \\n {y_train_proportions}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "96bea029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96420     There is construction work starting early in t...\n",
       "79745     Construction work without a permit. a door has...\n",
       "132263                                     Illegal unit....\n",
       "131793    Illegal work going on in basement area. work w...\n",
       "15135     Complainant is having problems with the neighb...\n",
       "                                ...                        \n",
       "18490     The manager/owner of the bldg. turns off water...\n",
       "101443    The property at 1654 kirkwood is an abandoned,...\n",
       "151227    Date last observed: 12-sep-19;    time last ob...\n",
       "142366    A 3-story building - outside lath has been det...\n",
       "91065     Construction debris -tar, tarps, exposed tar n...\n",
       "Name: complaint_description, Length: 142101, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e032cc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "48601d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Building Inspection Division', 'Code Enforcement Section',\n",
       "       'Housing Inspection Services', 'Plumbing Inspection Division'],\n",
       "      dtype='<U28')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fced6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, tokenizer):\n",
    "    input_ids, input_masks = [],[]\n",
    "    for sentence in tqdm(sentences):\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, \n",
    "                                       max_length=128,truncation=True,padding='max_length',\n",
    "                                       return_attention_mask=True,return_token_type_ids=True)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])      \n",
    "\n",
    "    return (tf.convert_to_tensor(input_ids), tf.convert_to_tensor(input_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "272ca0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc04ce3a9d74338b66d314ee399e53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e8d406aeaf43f88cb906dbce1cf171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b09e58e0d347b2830f3972b6a8b2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "X_train_input_ids, X_train_input_masks = tokenize(X_train,distilbert_tokenizer)\n",
    "X_val_input_ids, X_val_input_masks = tokenize(X_val,bert_tokenizer)\n",
    "X_test_input_ids, X_test_input_masks = tokenize(X_test,bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "070bbb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "DISTILBERT_DROPOUT = 0.2\n",
    "DISTILBERT_ATT_DROPOUT = 0.2\n",
    " \n",
    "# Configure DistilBERT's initialization\n",
    "config = DistilBertConfig(dropout=DISTILBERT_DROPOUT, \n",
    "                          attention_dropout=DISTILBERT_ATT_DROPOUT, \n",
    "                          output_hidden_states=True)\n",
    "                          \n",
    "#bare pre-trained DistilBERT model outputting raw hidden-states \n",
    "#needs head for classification\n",
    "distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
    "\n",
    "# Make DistilBERT layers untrainable\n",
    "for layer in distilbert.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c0876a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128\n",
    "LAYER_DROPOUT = 0.2\n",
    "LEARNING_RATE = 5e-5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def build_model(transformer, num_classes, max_length=MAX_LENGTH):\n",
    "    \n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    Builds a BERT model for classification tasks using a Hugging Face \n",
    "    transformer with no head attached.\n",
    "    \n",
    "    Input:\n",
    "      - transformer:  base Hugging Face transformer with no head.\n",
    "      - max_length:   Controls the maximum number of encoded tokens in \n",
    "                      a sequence.\n",
    "    \n",
    "    Output:\n",
    "      - model:        a compiled tf.keras.Model with added multi-class \n",
    "                      classification layerson top of the base Hugging Face \n",
    "                      transformer. \n",
    "    \"\"\"\"\"\"\"\"\"\"\"\n",
    "    \n",
    "    #define metrics to monitor\n",
    "    metrics = [\n",
    "                tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "\n",
    "    # define weight initializer with a random seed to ensure reproducibility\n",
    "    weight_initializer = tf.keras.initializers.GlorotNormal(seed=RANDOM_STATE) \n",
    "    \n",
    "    # define input layers\n",
    "    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n",
    "                                            name='input_ids', \n",
    "                                            dtype='int32')\n",
    "    input_masks_layer = tf.keras.layers.Input(shape=(max_length,), \n",
    "                                                  name='input_attention', \n",
    "                                                  dtype='int32')\n",
    "\n",
    "    \n",
    "\n",
    "    # tf.tensor representing the hidden-state of the model's last layer\n",
    "    last_hidden_state = transformer([input_ids_layer, input_masks_layer])[0]\n",
    "    \n",
    "    # We only care about BERT's output for the [CLS] token, \n",
    "    # which is located at index 0 of every encoded sequence.  \n",
    "    # Splicing out the [CLS] tokens gives us 2D data.\n",
    "    cls_token = last_hidden_state[:, 0, :]\n",
    "    \n",
    "    ##                                                 ##\n",
    "    ## Define additional dropout and dense layers here ##\n",
    "    ##                                                 ##\n",
    "    \n",
    "    # Define a single node that makes up the output layer (for binary classification)\n",
    "    output = tf.keras.layers.Dense(num_classes, \n",
    "                                   activation='softmax',\n",
    "                                   kernel_initializer=weight_initializer,  \n",
    "                                   kernel_constraint=None,\n",
    "                                   bias_initializer='zeros'\n",
    "                                   )(cls_token)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model([input_ids_layer, input_masks_layer], output)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3647037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(transformer=distilbert,num_classes=y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ae7b97fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_attention (InputLayer)    [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_7 (TFDisti TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
      "                                                                 input_attention[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_8 (Sli (None, 768)          0           tf_distil_bert_model_7[1][7]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            3076        tf.__operators__.getitem_8[0][0] \n",
      "==================================================================================================\n",
      "Total params: 66,365,956\n",
      "Trainable params: 3,076\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "64d40127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142101, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6f3d20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define callbacks for our model\n",
    "checkpoint = ModelCheckpoint(filepath=model_path+f'LSTM/model_{dt.datetime.now().strftime(\"%Y-%m-%d--%H:%M:%S\")}_best.h5', \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
    "\n",
    "callbacks = [checkpoint,\n",
    "             tqdm_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "57f87254",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 64\n",
    "NUM_STEPS = X_train_input_ids.shape[0] // BATCH_SIZE\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = [X_train_input_ids, X_train_input_masks],\n",
    "    y = y_train,\n",
    "    epochs = EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    steps_per_epoch = NUM_STEPS,\n",
    "    validation_data = ([X_val_input_ids, X_val_input_masks], y_val),\n",
    "    verbose=2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6218b05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x172103e50>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ab3b8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "# print(\"Evaluate model on test data\")\n",
    "y_pred = model.predict([X_test_input_ids, X_test_input_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(y_pred, axis=1) \n",
    "test_labels = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrix of our test predictions\n",
    "print(metrics.confusion_matrix(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b532bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classification report\n",
    "print(metrics.classification_report(test_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sf_building_complaints] *",
   "language": "python",
   "name": "conda-env-sf_building_complaints-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
